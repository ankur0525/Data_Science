{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###pandas\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mon    a\n",
       "tue    b\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##A parameter i  the name of ecpectd input to a function/method/class instantation\n",
    "##An arguemnet is the concrete value we provide during invocation\n",
    "\n",
    "fruits = [\"a\", \"b\"]\n",
    "day = [\"mon\", \"tue\"]\n",
    "\n",
    "pd.Series(data=fruits, index=day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import series with pd.read_csv files\n",
    "#pd.read_csv(\"file_name.csv\", usecols=[\"Name\"]).squeeze(\"columns\")\n",
    "#table.head(5)\n",
    "#len(table) -> 1000\n",
    "#type(table) -> Series\n",
    "#list(yable) -> convert to pythin list\n",
    "#sorted(table) -> ankur,basd,csfd,derdc,\n",
    "#dict(tabke) -> imdex-keys, column_data ->values\n",
    "#max(table), min(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in Keyword\n",
    "# in keyword checks if a value exists within an object\n",
    "# \"car\" in \"first_car\"  or 2 in [1,2,3,4,5,6]\n",
    "'''\n",
    "\"Bulbasur\" in pokemon -> False\n",
    "0 in pokemon -> True\n",
    "5 in pokemon.index -> True\n",
    "\n",
    "\"Bulbasaur\" in pokemon.values -> True\n",
    "'''\n",
    "\n",
    "## sort_values (by default ascending)\n",
    "#table.sort_values(ascending=True)\n",
    "\n",
    "## sort_index sorts a series by it's index\n",
    "#Task:return to original indexing -> table.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######Good Question##############################\n",
    "\n",
    "# This challenge includes a coffee.csv with 2 columns: \n",
    "# Coffee and Calories. Import the CSV. Assign the Coffee\n",
    "# column to be the index and the Calories column to be the\n",
    "# Series' values. Assign the Series to a 'coffee' variable.\n",
    "coffee = pd.read_csv(\"coffee.csv\", index_col = \"Coffee\").squeeze(\"columns\")\n",
    " \n",
    "# Check whether the coffee 'Flat White' is present in the data.\n",
    "# Assign the result to a `flat_white` variable\n",
    "flat_white = \"Flat White\" in coffee.index\n",
    " \n",
    "# Check whether the coffee 'Cortado' is present in the data.\n",
    "# Assign the result to a `cortado` variable\n",
    "cortado = \"Cortado\" in coffee.index\n",
    " \n",
    "# Check whether the coffee 'Blackberry Mocha' is present in the data.\n",
    "# Assign the result to a `blackberry_mocha` variable\n",
    "blackberry_mocha = \"Blackberry Mocha\" in coffee.index\n",
    " \n",
    "# Check whether the value 221 is present in the data.\n",
    "# Assign the result to a 'high_calorie' variable.\n",
    "high_calorie = 221 in coffee.values\n",
    " \n",
    "# Check whether the value 400 is present in the data.\n",
    "# Assign the result to a 'super_high_calorie' variable.\n",
    "super_high_calorie = 400 in coffee.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extract series value by index position\n",
    "\n",
    "#pokemon.iloc[251]\n",
    "#pokemon.iloc[100,200,300]\n",
    "#pokemon.iloc[27:36] #total values = 36-27 = 9\n",
    "#pokempon.iloc[-1] # last value\n",
    "#pokempn.iloc[-8:] #last 8th value to the last value\n",
    "\n",
    "#extract series value by index label\n",
    "#pokemon.loc[\"Pichu\"]\n",
    "#pokemon.loc[\"Pichu\",\"Abra\",\"Squirtle\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get method\n",
    "# alternate to extract value by index label. alternative option to square backet\n",
    "# get method's 2nd arguement sets the fallback value to return if the label/position deosn't exist\n",
    "\n",
    "#pokemon.get(\"abra\") = pokemon.loc[\"abra\"]\n",
    "# if the get method doesm't found anything, it returns none (or we can modify), whereas loc give error\n",
    "#pokemon.get([\"moltres\", \"articuno\"])\n",
    "#pokemon.get(\"digimon\", \"this is a not a pokemon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###overwrite a series value\n",
    "\n",
    "#pokemon.iloc[0] = \"NEw_pokeom\"\n",
    "#pokemon.iloc[1,2,4] = [\"fireasd\", \"dragonbie\", \"sadsd\"]\n",
    "\n",
    "#pokemon = pd.read_csv(\"pokemon.csv\", index_col=\"Name\").squeeze(\"columns\") ##pokemon.csv has 2 coluns \"name\" and \"type\"\n",
    "#pokemon.loc[\"evee\"] = \"fairy\" -> will chaneg the type of evee to fairy\n",
    "#pokemon.iloc[0] = \"dark\" -> will chaneg the type of pokemon at index 0 to dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Copy method\n",
    "# duoplicate iof an object, changing copy will not going to have an effect on original object\n",
    "# whereras view is segment of a an object, changing will modify the original data\n",
    "\n",
    "#pokemon_df = pd.read_csv(\"pokemon.csv\", usecols=\"Name\").squeeze(\"columns\") #pokemon.csv has 2 coluns \"name\" and \"type\". it will only pick up name column  ##this is a dataframe\n",
    "#pokemon_Series = pokemon_df.squeeze(\"columns\") ##this is a series\n",
    "##pokemon_series is a view of pokemon_df. Changing pokemon_series will change pokemon_df\n",
    "#pokemon_series[0] = \"what\" -> this will be obsrerved ib pokemon_df also\n",
    "#pokemon_Series = pokemon_df.squeeze(\"columns\").copy() ##this is a series and a copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Math methods\n",
    "# count,sum,product,mean,std,max,min,median,mode,describe\n",
    "\n",
    "#table.count() is not gonna count Nan values, but #table.size() will count Nan values\n",
    "#table.describe() -> gives a lot of useful information\n",
    "\n",
    "##Broadcasting\n",
    "# appplying a mathematical operation to all the values\n",
    "# google is a Df having stock price values\n",
    "#google.add(10) or google + 10\n",
    "#google.sub(10) or google - 10\n",
    "#google.mul(1.25) or google * 1.25\n",
    "#google.div(2) google / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##value_counts menthod\n",
    "# the value_counts method returns the no. of time unique value occurs\n",
    "# the normarlize paramter returns the relative frequencies/percentage of values instead of the counts\n",
    "\n",
    "#pokemon = pd.read_csv(\"pokemon.csv\", index_col=\"Name\").squeeze(\"columns\")\n",
    "#pokemon.value_counts() #ascending=False (by default) ##can be used to count the no. of types of pokeomn\n",
    "#pokemon.value_counts(ascending=True) \n",
    "#pokemon.value_counts(normalize = True)\n",
    "#pokemon.value_counts(normalize = True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##apply method\n",
    "# the apply method accepts a function. It involves that function on every Series value.\n",
    "\n",
    "#pokemon = pd.read_csv(\"pokemon.csv\", usecols=\"Name\").squeeze(\"columns\")\n",
    "#pokemon.apply(len)\n",
    "#we can define our own function also\n",
    "def count_of_a(pokemon):\n",
    "    pokemon.count(\"a\") ##count the no. of alphabet \"a\" in the name\n",
    "\n",
    "#pokemon.apply(count_of_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Map method\n",
    "# map method \"maps\" or connects each Series to another value\n",
    "# We can pass method a dict. or a series. Both types connects key to values\n",
    "# The map method uses our arguements to connect or bridge together the values\n",
    "\n",
    "#pokemon = pd.read_csv(\"pokemon.csv\", index_col=\"Name\").squeeze(\"columns\")\n",
    "attack_powers = {\n",
    "    \"Grass\": 10,\n",
    "    \"Fire\": 15,\n",
    "    \"Water\": 15,\n",
    "    \"Fairy, Fighting\":20\n",
    "}\n",
    "#pokemon.map(attack_powers) ##if attack doesn't match, it will give Nan value for that type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Methods and attributes b/w series and dataframes\n",
    "# dataframe is a 2-d table consisting of rows and columns.\n",
    "# pandas uses a Nan for cells that have missing values. Most operations with Nan will give Nan\n",
    "# Like a series, pandas assigns an index position/label to each dataframe row\n",
    "# The Dataframes and Series have common and exclusive methods/attributes\n",
    "# the hasnas attribute exists only a Series. The columns attribute exists only on DataFrame\n",
    "# some methods/attributes will return diff. types of data\n",
    "# The info method returns a summary of the pandas object\n",
    "\n",
    "#nba = pd.read_csv(\"nba.csv\") -> Df\n",
    "#s =pd.Series([1,2,3,4,5]) -> Series\n",
    "\n",
    "#nba.head() , nba.tail()\n",
    "#s.index , nba.index()\n",
    "#s.values, nba.values()\n",
    "#s.shape() , nba.shape()\n",
    "#s.dtypes(), nba.dtypes()\n",
    "#s.hasnas()\n",
    "#nba.columns()  \n",
    "#s.axes, nba.axes()\n",
    "#s.info(), nba.info()\n",
    "\n",
    "##difference b/w shared methods (#45)\n",
    "# the summ methods adds a Series's values. On a Df, the sum method defaults to adding the values bys traversing the index(row values)\n",
    "# the axis parameter customizes the direction that we add across. Pass \"columns\" or 1 to add \"across\" the the columns\n",
    "\n",
    "# revenue is a Df\n",
    "#s = pd.Series(1,2,3) #s.sum() -> 6\n",
    "#revenue.sum() = revenue.sum(axis = \"index\")-> gives sum of all the values of that column (across the rows)\n",
    "#revenue.sum(axis = \"columns\") -> sum across the columns\n",
    "#revenue.sum(axis = \"columns\").sum() -> sum of all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Selecting a single column from df\n",
    "# we can use df.coulmn_name to etract a single columns, but syntax will not work if column name has space in between\n",
    "# We can also use [] to extract column from dataframe. df[\"column name\"]\n",
    "# Pandas extracts a column as a series from a DF\n",
    "# The Series is a view, so changes to the Series will affect the Data Frame\n",
    "# Pds will dipslay a warning if ypu try to mutilitate the Sereis, use the copy method to create a duplicate\n",
    "\n",
    "#nba.Team\n",
    "#nba.Name - okay , but nba.name - error as column name is \"Name\"\n",
    "#type(nba[\"Name\"])\n",
    "#names = nba[\"Name\"].copy() ,now we can modify this copy without affecting the original datframe\n",
    "\n",
    "###Selecting Multiple columns\n",
    "#result = nba[[\"Team\", \"Name\"]] # result is a Df object, which is a copy\n",
    "\n",
    "##Add a new column\n",
    "#nba[\"Sport\"] = \"Basketball\" -> It will add a new column Sport in which all vaues is Sport\n",
    "#nba.insert(loc = 3, cloumn=\"Sport\", value = \"Basketball\") #another method to add column, we can select the column position \n",
    "\n",
    "#nba[\"Salary Doubled\"] = nba[\"salary\"].mul(2)\n",
    "\n",
    "##review of value_counts method\n",
    "#nba[\"team\"].value_counts()\n",
    "#nba[\"position\"].value_counts()\n",
    "#nba[\"position\"].value_counts(normalize=True) *100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop datarows with missing values\n",
    "# pandas uses Nan designation for missing values\n",
    "# the dropna method deletes rows with missing values. it's default behaviour is to drop a row, if it has misisng value\n",
    "# pass the how parameter, an arguement of \"all\" to delete rows where all values are Nan\n",
    "# The subset paramter customizes/limits the colums that pandas will use to drop rows with missing values\n",
    "\n",
    "\"\"\"Suppose nba table has these 3 rows\n",
    "index player salray position age \n",
    "0   kohli   10      2nd     30 \n",
    "1   rohit   20      1st     Nan\n",
    "2   Nan   Nan       Nan     Nan\n",
    "\"\"\"\n",
    "#nba.dropna() or nba.dropna(how=\"any\") -> remove any rows that have misisng values (will delete row 2 and 3)\n",
    "\n",
    "#nba.dropna(how=\"all\")  -> remove only that row which has all value= Nan, only remove row 3\n",
    "#nba.dropna(subset=[\"salray\"]) -> reomeve only that row which has Nan value in slaray column only\n",
    "#nba.dropna(subset=[\"salray\" , \"age\"]) -> removes only those rows which have Nan values in salray *or* age column. (Works as \"or\" orperator, not as \"and\" operator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filling values\n",
    "#fillna value replaces both series and dataframe.\n",
    "#An etracted series is a view of the orginal Df, but the fillna method returns a copy\n",
    "\n",
    "#nba.fillna(0)\n",
    "#nba[\"Salary\"] = nba[\"Salary\"].fillna(0)\n",
    "#nba[\"Salary\"] = nba[\"Salary\"].fillna(value=\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##astype method 1\n",
    "# The astype method converts a Series's value to the specified type.\n",
    "# Pass in the specified type as either as string or the core Python data type\n",
    "# Pandas cannot convetr Nan values to numeric types, so we need to eliminate/replace them before we perform the conversion\n",
    "# The dtypes atribute returns a Series with DataFrame's columns and types \n",
    "\n",
    "#nba.dtypes()\n",
    "#nba[\"Salary\"].astype(\"int\") or nba[\"Salary\"].astype(int) -> this is a copy, original won;t change\n",
    "#nba[\"Salary\"] = nba[\"Salary\"].astype(\"int\")\n",
    "\n",
    "##astype methdo 2\n",
    "# The category type is ideal for columns with limited no. of unique values\n",
    "# the nunique method will return a Series with the no. of unqiues values in each column\n",
    "# With categories, pandas does not create a separate value in memory for each \"cell\". Rather, the cells point to a single copy for each unique value\n",
    "# This reduces a great amount of memeory cinsumption based on repeated values\n",
    "\n",
    "#nba[\"Team\"].nuinque()\n",
    "#nba.unique()\n",
    "#nba[\"Team\"] = nba[\"Team\"].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sort a Df with sort_values method 1\n",
    "# The sort_values method sorts a DF by the values in 1 or more columns. The default sort in an ascending one(alphabetical or string)\n",
    "# The 1st parameter(by) expects the column(s) to sort by.\n",
    "# if sorting by a single column, pass a string with it's name\n",
    "# the ascending parameter custmizesthe sort order\n",
    "# the na_position parameter customizes where pandas places NaN values.\n",
    "\n",
    "#nba.sort_values(\"Name\") = nba.sort_values(by=\"Name\")  #by default ascending\n",
    "#nba.sort_values(by=\"Name\", ascending=False) #by default pandas put Nan values at last\n",
    "#nba.sort_values(by=\"Name\", na_positiion=\"first\", ascending = \"False\") \n",
    "\n",
    "# the above one is used for only 1 column, now we are going to sort multiple columns\n",
    "# To sort multiple columns, in by parameter give multiple column names\n",
    "# Pass ascending a list to customize the sort order of columns. len of by multiple columns = len of ascending list\n",
    "\n",
    "#nba.sort_values(by=[\"Team\",\"Name\"]) #1st sort the values by Team then Name \n",
    "#nba.sort_values(by=[\"Team\",\"Name\"], ascending=True) ->asc=True will aplly to all columns\n",
    "#nba.sort_values(by=[\"Team\",\"Name\"], ascending=[True,False]) -> asc=True will apply to team and asc=False will apply to Name\n",
    "#nba = nba.sort_values(by=[\"Team\",\"Name\"], ascending=[True,False] #will apply changes to the df\n",
    "\n",
    "##sort_index Method\n",
    "# sort by index positions/labels\n",
    "\n",
    "#nba = nba.sort_index() ->Pandas will sort the index of any type int,date,alph in ascending order\n",
    "#nba = nba.sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rank Values with rank method\n",
    "# The rank method assigns a numeric rating to each Series Value\n",
    "# Pds will assign the same rank to equla values and create a \"gap\" in datasets for the ranks\n",
    "\n",
    "#nba = pd.read_csv(\"nba.csv\").dropna(how=\"all\")\n",
    "#nba[\"Salary\"] = nba[\"Salary\"].fillna[0].astype(int)\n",
    "#nba[\"Salary\"].rank()\n",
    "#nba[\"Salary\"].rank(ascending = False).astype(int) -> for descedning order, astype(int) is uesd to convert rnk type from float to int\n",
    "#nba[\"Salary]= nba[\"Salary\"].rank(ascending = False).astype(int) -> making changes in original df\n",
    "#nba.sort_values(by= \"Salary\", ascending=false).head(10) -> to confirm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
